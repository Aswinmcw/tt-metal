{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arakhmati/tt-metal/build/python_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m                  Metal\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Initializing device 0\n",
      "\u001b[38;2;000;128;000m                 Device\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Opening device driver\n",
      "\u001b[32m2023-10-24 19:09:42.219\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Detected 4 PCI devices\n",
      "\u001b[32m2023-10-24 19:09:42.246\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Using 1 Hugepages/NumHostMemChannels for TTDevice (pci_interface_id: 3 device_id: 0xfaca revision: 0)\n",
      "\u001b[32m2023-10-24 19:09:42.252\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Using 1 Hugepages/NumHostMemChannels for TTDevice (pci_interface_id: 2 device_id: 0xfaca revision: 0)\n",
      "\u001b[32m2023-10-24 19:09:42.256\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Using 1 Hugepages/NumHostMemChannels for TTDevice (pci_interface_id: 1 device_id: 0xfaca revision: 0)\n",
      "\u001b[32m2023-10-24 19:09:42.264\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Using 1 Hugepages/NumHostMemChannels for TTDevice (pci_interface_id: 0 device_id: 0xfaca revision: 0)\n",
      "\u001b[32m2023-10-24 19:09:42.298\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Detected 4 PCI devices\n",
      "\u001b[32m2023-10-24 19:09:42.299\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Using 1 Hugepages/NumHostMemChannels for TTDevice (pci_interface_id: 3 device_id: 0xfaca revision: 0)\n",
      "\u001b[32m2023-10-24 19:09:42.303\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Using 1 Hugepages/NumHostMemChannels for TTDevice (pci_interface_id: 2 device_id: 0xfaca revision: 0)\n",
      "\u001b[32m2023-10-24 19:09:42.307\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Using 1 Hugepages/NumHostMemChannels for TTDevice (pci_interface_id: 1 device_id: 0xfaca revision: 0)\n",
      "\u001b[32m2023-10-24 19:09:42.311\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Using 1 Hugepages/NumHostMemChannels for TTDevice (pci_interface_id: 0 device_id: 0xfaca revision: 0)\n",
      "\u001b[32m2023-10-24 19:09:42.369\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Disable PCIE DMA\n",
      "\u001b[32m2023-10-24 19:09:42.369\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Disable PCIE DMA\n",
      "\u001b[32m2023-10-24 19:09:42.369\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Disable PCIE DMA\n",
      "\u001b[32m2023-10-24 19:09:42.369\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Disable PCIE DMA\n",
      "\u001b[38;2;000;128;000m                  Metal\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | AI CLK for device 0 is:   1202 MHz\n"
     ]
    }
   ],
   "source": [
    "import tt_lib as ttl\n",
    "device_id = 0\n",
    "device = ttl.device.CreateDevice(device_id)\n",
    "ttl.device.SetDefaultDevice(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ttnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "sequence_size = 64\n",
    "num_heads = 4\n",
    "head_size = 32\n",
    "hidden_size = num_heads * head_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize activations and weights using torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_hidden_states = torch.randn((batch_size, sequence_size, hidden_size), dtype=torch.bfloat16)\n",
    "\n",
    "torch_attention_mask = torch.zeros((1, 1, 1, sequence_size), dtype=torch.bfloat16)\n",
    "torch_attention_mask[:, :, ::2, :] = -1e9\n",
    "\n",
    "torch_query_weight = torch.randn((hidden_size, hidden_size), dtype=torch.bfloat16)\n",
    "torch_query_bias = torch.randn((1, 1, 1, hidden_size), dtype=torch.bfloat16)\n",
    "torch_key_weight = torch.randn((hidden_size, hidden_size), dtype=torch.bfloat16)\n",
    "torch_key_bias = torch.randn((1, 1, 1, hidden_size), dtype=torch.bfloat16)\n",
    "torch_value_weight = torch.randn((hidden_size, hidden_size), dtype=torch.bfloat16)\n",
    "torch_value_bias = torch.randn((1, 1, 1, hidden_size), dtype=torch.bfloat16)\n",
    "torch_output_weight = torch.randn((hidden_size, hidden_size), dtype=torch.bfloat16)\n",
    "torch_output_bias = torch.randn((1, 1, 1, hidden_size), dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert activations and weights to ttnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states = ttnn.from_torch(torch_hidden_states)\n",
    "attention_mask = ttnn.from_torch(torch_attention_mask)\n",
    "\n",
    "query_weight = ttnn.from_torch(torch_query_weight)\n",
    "query_bias = ttnn.from_torch(torch_query_bias)\n",
    "key_weight = ttnn.from_torch(torch_key_weight)\n",
    "key_bias = ttnn.from_torch(torch_key_bias)\n",
    "value_weight = ttnn.from_torch(torch_value_weight)\n",
    "value_bias = ttnn.from_torch(torch_value_bias)\n",
    "output_weight = ttnn.from_torch(torch_output_weight)\n",
    "output_bias = ttnn.from_torch(torch_output_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write multi_head_attention using ttnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_head_attention(\n",
    "    hidden_states,\n",
    "    attention_mask,\n",
    "    query_weight,\n",
    "    query_bias,\n",
    "    key_weight,\n",
    "    key_bias,\n",
    "    value_weight,\n",
    "    value_bias,\n",
    "    output_weight,\n",
    "    output_bias,\n",
    "    *,\n",
    "    head_size,\n",
    "):\n",
    "    batch_size, sequence_size, hidden_size = hidden_states.shape\n",
    "    num_heads = hidden_size // head_size\n",
    "\n",
    "    query = hidden_states @ query_weight\n",
    "    query = query + query_bias\n",
    "    query = ttnn.reshape(query, (batch_size, sequence_size, num_heads, head_size))\n",
    "    query = ttnn.permute(query, (0, 2, 1, 3))\n",
    "\n",
    "    key = hidden_states @ key_weight\n",
    "    key = key + key_bias\n",
    "    key = ttnn.reshape(key, (batch_size, sequence_size, num_heads, head_size))\n",
    "    key = ttnn.permute(key, (0, 2, 3, 1))\n",
    "\n",
    "    value = hidden_states @ value_weight\n",
    "    value = value + value_bias\n",
    "    value = ttnn.reshape(value, (batch_size, sequence_size, num_heads, head_size))\n",
    "    value = ttnn.permute(value, (0, 2, 1, 3))\n",
    "\n",
    "    attention_scores = query @ key\n",
    "    attention_scores = attention_scores * (1 / (head_size**0.5))\n",
    "    if attention_mask is not None:\n",
    "        attention_scores = attention_scores + attention_mask\n",
    "\n",
    "    attention_probs = ttnn.softmax(attention_scores, dim=-1)\n",
    "\n",
    "    context_layer = attention_probs @ value\n",
    "    context_layer = ttnn.permute(context_layer, (0, 2, 1, 3))\n",
    "    context_layer = ttnn.reshape(context_layer, (batch_size, sequence_size, hidden_size))\n",
    "\n",
    "    self_output = context_layer @ output_weight\n",
    "    self_output = self_output + output_bias\n",
    "\n",
    "    return self_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run using ttnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-24 19:09:43.311 | WARNING  | ttnn.core:reshape:159 - Given reshape operation could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-24 19:09:43.314 | WARNING  | ttnn.core:reshape:159 - Given reshape operation could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-24 19:09:44.089 | WARNING  | ttnn.core:reshape:159 - Given reshape operation could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-24 19:09:44.093 | WARNING  | ttnn.core:permute:170 - Given permute operation could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-24 19:09:44.096 | WARNING  | ttnn.core:reshape:159 - Given reshape operation could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-24 19:09:44.098 | WARNING  | ttnn.core:reshape:159 - Given reshape operation could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-24 19:09:44.103 | WARNING  | ttnn.core:reshape:159 - Given reshape operation could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-24 19:09:44.104 | WARNING  | ttnn.core:permute:170 - Given permute operation could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-24 19:09:44.106 | WARNING  | ttnn.core:reshape:159 - Given reshape operation could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-24 19:09:44.108 | WARNING  | ttnn.core:reshape:159 - Given reshape operation could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-24 19:09:44.112 | WARNING  | ttnn.core:reshape:159 - Given reshape operation could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-24 19:09:44.112 | WARNING  | ttnn.core:permute:170 - Given permute operation could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-24 19:09:46.005 | WARNING  | ttnn.core:reshape:159 - Given reshape operation could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-24 19:09:46.008 | WARNING  | ttnn.core:reshape:159 - Given reshape operation could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-24 19:09:46.011 | WARNING  | ttnn.core:reshape:159 - Given reshape operation could not be run on the TT device. Defaulting to torch implementation\n"
     ]
    }
   ],
   "source": [
    "output = multi_head_attention(\n",
    "    hidden_states,\n",
    "    attention_mask,\n",
    "    query_weight,\n",
    "    query_bias,\n",
    "    key_weight,\n",
    "    key_bias,\n",
    "    value_weight,\n",
    "    value_bias,\n",
    "    output_weight,\n",
    "    output_bias,\n",
    "    head_size=head_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing ttnn tensor\n",
      "[1, 1, 64, 128]\n",
      "Tensor([ [-3.01562, 0.925781, 19.875, -19.25, 18.625, 7.65625, 14.75, -8.25, 0.21875, -14.4375, 7.25, -5.59375, 26.125, 26, 1.20312, 31.5, -14.8125, -16.625, -0.226562, 33.25, -1.33594, 5.3125, 8.8125, -12.9375, 2.73438, 9.875, 0.722656, -39, -9.125, -38.5, -29.625, 11.125, 33, 6.03125, 19, -24.125, 3.40625, -59.5, 13.8125, 3.75, -15, 51.25, -14.5, -25.25, 30.75, -31.625, 26.75, 43, 13.25, -18.625, 12.875, -20, -10.125, -5.3125, 35.5, 3.78125, -14.3125, -15.75, -23.25, -36.25, -2.29688, -1.71094, -6.75, -16.75, 13.75, -0.535156, -42.25, -26, -15.125, -39, -0.625, -5.84375, -6.625, 10.6875, -21.75, -0.015625, 5.6875, -52.5, 17.875, 54.75, 1.11719, 7.125, -34.25, 1.69531, 8.5, 13.6875, -15.1875, 11.625, -0.546875, -2.57812, -18.125, -16, -0.445312, -7.8125, 30.25, -13, 21.5, 0.714844, -15.9375, 3.96875, 10.5625, 1.46875, 19.5, 10.625, -0.296875, -6.9375, -2.48438, 1.61719, -9.5625, -11.75, -10.6875, -15.625, 35.25, 1.42969, -4.75, 9.9375, -24.375, 56.5, -11.9375, 14.9375, -20.875, -0.503906, 5.28125, 3.20312, -22.625, -1.85938, -13.0625, -4.84375]], dtype=bfloat16 )\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Printing torch tensor\n",
      "torch.Size([1, 1, 64, 128])\n",
      "tensor([[-3.0156e+00,  9.2578e-01,  1.9875e+01, -1.9250e+01,  1.8625e+01,\n",
      "          7.6562e+00,  1.4750e+01, -8.2500e+00,  2.1875e-01, -1.4438e+01,\n",
      "          7.2500e+00, -5.5938e+00,  2.6125e+01,  2.6000e+01,  1.2031e+00,\n",
      "          3.1500e+01, -1.4812e+01, -1.6625e+01, -2.2656e-01,  3.3250e+01,\n",
      "         -1.3359e+00,  5.3125e+00,  8.8125e+00, -1.2938e+01,  2.7344e+00,\n",
      "          9.8750e+00,  7.2266e-01, -3.9000e+01, -9.1250e+00, -3.8500e+01,\n",
      "         -2.9625e+01,  1.1125e+01,  3.3000e+01,  6.0312e+00,  1.9000e+01,\n",
      "         -2.4125e+01,  3.4062e+00, -5.9500e+01,  1.3812e+01,  3.7500e+00,\n",
      "         -1.5000e+01,  5.1250e+01, -1.4500e+01, -2.5250e+01,  3.0750e+01,\n",
      "         -3.1625e+01,  2.6750e+01,  4.3000e+01,  1.3250e+01, -1.8625e+01,\n",
      "          1.2875e+01, -2.0000e+01, -1.0125e+01, -5.3125e+00,  3.5500e+01,\n",
      "          3.7812e+00, -1.4312e+01, -1.5750e+01, -2.3250e+01, -3.6250e+01,\n",
      "         -2.2969e+00, -1.7109e+00, -6.7500e+00, -1.6750e+01,  1.3750e+01,\n",
      "         -5.3516e-01, -4.2250e+01, -2.6000e+01, -1.5125e+01, -3.9000e+01,\n",
      "         -6.2500e-01, -5.8438e+00, -6.6250e+00,  1.0688e+01, -2.1750e+01,\n",
      "         -1.5625e-02,  5.6875e+00, -5.2500e+01,  1.7875e+01,  5.4750e+01,\n",
      "          1.1172e+00,  7.1250e+00, -3.4250e+01,  1.6953e+00,  8.5000e+00,\n",
      "          1.3688e+01, -1.5188e+01,  1.1625e+01, -5.4688e-01, -2.5781e+00,\n",
      "         -1.8125e+01, -1.6000e+01, -4.4531e-01, -7.8125e+00,  3.0250e+01,\n",
      "         -1.3000e+01,  2.1500e+01,  7.1484e-01, -1.5938e+01,  3.9688e+00,\n",
      "          1.0562e+01,  1.4688e+00,  1.9500e+01,  1.0625e+01, -2.9688e-01,\n",
      "         -6.9375e+00, -2.4844e+00,  1.6172e+00, -9.5625e+00, -1.1750e+01,\n",
      "         -1.0688e+01, -1.5625e+01,  3.5250e+01,  1.4297e+00, -4.7500e+00,\n",
      "          9.9375e+00, -2.4375e+01,  5.6500e+01, -1.1938e+01,  1.4938e+01,\n",
      "         -2.0875e+01, -5.0391e-01,  5.2812e+00,  3.2031e+00, -2.2625e+01,\n",
      "         -1.8594e+00, -1.3062e+01, -4.8438e+00]], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "print(\"Printing ttnn tensor\")\n",
    "print(output.shape)\n",
    "print(output[0, 0, :1])\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Printing torch tensor\")\n",
    "torch_output = ttnn.to_torch(output)\n",
    "print(torch_output.shape)\n",
    "print(torch_output[0, 0, :1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m                  Metal\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Closing device 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttl.device.CloseDevice(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
