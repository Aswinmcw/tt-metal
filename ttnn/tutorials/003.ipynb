{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/git/tt-metal/build/python_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m                  Metal\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Initializing device 0\n",
      "\u001b[38;2;000;128;000m                 Device\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Opening device driver\n",
      "\u001b[32m2023-10-25 15:53:16.862\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Detected 1 PCI device\n",
      "\u001b[32m2023-10-25 15:53:16.873\u001b[0m | \u001b[1m\u001b[38;2;255;165;000mWARNING \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - init_detect_tt_device_numanodes(): Could not determine NumaNodeSet for TT device (physical_device_id: 0 pci_bus_id: 0000:00:08.0)\n",
      "\u001b[32m2023-10-25 15:53:16.873\u001b[0m | \u001b[1m\u001b[38;2;255;165;000mWARNING \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Could not find NumaNodeSet for TT Device (physical_device_id: 0 pci_bus_id: 0000:00:08.0)\n",
      "\u001b[32m2023-10-25 15:53:16.873\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Using 1 Hugepages/NumHostMemChannels for TTDevice (pci_interface_id: 0 device_id: 0xfaca revision: 0)\n",
      "\u001b[32m2023-10-25 15:53:16.874\u001b[0m | \u001b[1m\u001b[38;2;255;165;000mWARNING \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - bind_area_memory_nodeset(): Unable to determine TT Device to NumaNode mapping for physical_device_id: 0. Skipping membind.\n",
      "\u001b[0;33m---- ttSiliconDevice::init_hugepage: bind_area_to_memory_nodeset() failed (physical_device_id: 0 ch: 0). Hugepage allocation is not on NumaNode matching TT Device. Side-Effect is decreased Device->Host perf (Issue #893).\n",
      "\u001b[0m\u001b[32m2023-10-25 15:53:17.092\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Detected 1 PCI device\n",
      "\u001b[32m2023-10-25 15:53:17.093\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Using 1 Hugepages/NumHostMemChannels for TTDevice (pci_interface_id: 0 device_id: 0xfaca revision: 0)\n",
      "\u001b[32m2023-10-25 15:53:17.094\u001b[0m | \u001b[1m\u001b[38;2;255;165;000mWARNING \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - bind_area_memory_nodeset(): Unable to determine TT Device to NumaNode mapping for physical_device_id: 0. Skipping membind.\n",
      "\u001b[0;33m---- ttSiliconDevice::init_hugepage: bind_area_to_memory_nodeset() failed (physical_device_id: 0 ch: 0). Hugepage allocation is not on NumaNode matching TT Device. Side-Effect is decreased Device->Host perf (Issue #893).\n",
      "\u001b[0m\u001b[32m2023-10-25 15:53:17.230\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Disable PCIE DMA\n",
      "\u001b[38;2;000;128;000m                  Metal\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | AI CLK for device 0 is:   1202 MHz\n"
     ]
    }
   ],
   "source": [
    "import tt_lib as ttl\n",
    "device_id = 0\n",
    "device = ttl.device.CreateDevice(device_id)\n",
    "ttl.device.SetDefaultDevice(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ttnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "sequence_size = 64\n",
    "num_heads = 4\n",
    "head_size = 32\n",
    "hidden_size = num_heads * head_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize activations and weights using torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_hidden_states = torch.randn((batch_size, sequence_size, hidden_size), dtype=torch.bfloat16)\n",
    "\n",
    "torch_attention_mask = torch.zeros((1, 1, 1, sequence_size), dtype=torch.bfloat16)\n",
    "torch_attention_mask[:, :, ::2, :] = -1e9\n",
    "\n",
    "torch_query_weight = torch.randn((hidden_size, hidden_size), dtype=torch.bfloat16)\n",
    "torch_query_bias = torch.randn((1, 1, 1, hidden_size), dtype=torch.bfloat16)\n",
    "torch_key_weight = torch.randn((hidden_size, hidden_size), dtype=torch.bfloat16)\n",
    "torch_key_bias = torch.randn((1, 1, 1, hidden_size), dtype=torch.bfloat16)\n",
    "torch_value_weight = torch.randn((hidden_size, hidden_size), dtype=torch.bfloat16)\n",
    "torch_value_bias = torch.randn((1, 1, 1, hidden_size), dtype=torch.bfloat16)\n",
    "torch_output_weight = torch.randn((hidden_size, hidden_size), dtype=torch.bfloat16)\n",
    "torch_output_bias = torch.randn((1, 1, 1, hidden_size), dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert activations and weights to ttnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states = ttnn.from_torch(torch_hidden_states)\n",
    "attention_mask = ttnn.from_torch(torch_attention_mask)\n",
    "\n",
    "query_weight = ttnn.from_torch(torch_query_weight)\n",
    "query_bias = ttnn.from_torch(torch_query_bias)\n",
    "key_weight = ttnn.from_torch(torch_key_weight)\n",
    "key_bias = ttnn.from_torch(torch_key_bias)\n",
    "value_weight = ttnn.from_torch(torch_value_weight)\n",
    "value_bias = ttnn.from_torch(torch_value_bias)\n",
    "output_weight = ttnn.from_torch(torch_output_weight)\n",
    "output_bias = ttnn.from_torch(torch_output_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write multi_head_attention using ttnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_head_attention(\n",
    "    hidden_states,\n",
    "    attention_mask,\n",
    "    query_weight,\n",
    "    query_bias,\n",
    "    key_weight,\n",
    "    key_bias,\n",
    "    value_weight,\n",
    "    value_bias,\n",
    "    output_weight,\n",
    "    output_bias,\n",
    "    *,\n",
    "    head_size,\n",
    "):\n",
    "    batch_size, sequence_size, hidden_size = hidden_states.shape\n",
    "    num_heads = hidden_size // head_size\n",
    "\n",
    "    query = hidden_states @ query_weight\n",
    "    query = query + query_bias\n",
    "    query = ttnn.reshape(query, (batch_size, sequence_size, num_heads, head_size))\n",
    "    query = ttnn.permute(query, (0, 2, 1, 3))\n",
    "\n",
    "    key = hidden_states @ key_weight\n",
    "    key = key + key_bias\n",
    "    key = ttnn.reshape(key, (batch_size, sequence_size, num_heads, head_size))\n",
    "    key = ttnn.permute(key, (0, 2, 3, 1))\n",
    "\n",
    "    value = hidden_states @ value_weight\n",
    "    value = value + value_bias\n",
    "    value = ttnn.reshape(value, (batch_size, sequence_size, num_heads, head_size))\n",
    "    value = ttnn.permute(value, (0, 2, 1, 3))\n",
    "\n",
    "    attention_scores = query @ key\n",
    "    attention_scores = attention_scores * (1 / (head_size**0.5))\n",
    "    if attention_mask is not None:\n",
    "        attention_scores = attention_scores + attention_mask\n",
    "\n",
    "    attention_probs = ttnn.softmax(attention_scores, dim=-1)\n",
    "\n",
    "    context_layer = attention_probs @ value\n",
    "    context_layer = ttnn.permute(context_layer, (0, 2, 1, 3))\n",
    "    context_layer = ttnn.reshape(context_layer, (batch_size, sequence_size, hidden_size))\n",
    "\n",
    "    self_output = context_layer @ output_weight\n",
    "    self_output = self_output + output_bias\n",
    "\n",
    "    return self_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run using ttnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 15:53:19.380 | WARNING  | ttnn.core:reshape:244 - Given reshape operation could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-25 15:53:19.385 | WARNING  | ttnn.core:permute:254 - Given permute operation could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-25 15:53:19.403 | WARNING  | ttnn.core:reshape:244 - Given reshape operation could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-25 15:53:19.406 | WARNING  | ttnn.core:permute:254 - Given permute operation could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-25 15:53:19.424 | WARNING  | ttnn.core:reshape:244 - Given reshape operation could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-25 15:53:19.427 | WARNING  | ttnn.core:permute:254 - Given permute operation could not be run on the TT device. Defaulting to torch implementation\n"
     ]
    }
   ],
   "source": [
    "output = multi_head_attention(\n",
    "    hidden_states,\n",
    "    attention_mask,\n",
    "    query_weight,\n",
    "    query_bias,\n",
    "    key_weight,\n",
    "    key_bias,\n",
    "    value_weight,\n",
    "    value_bias,\n",
    "    output_weight,\n",
    "    output_bias,\n",
    "    head_size=head_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing ttnn tensor\n",
      "[1, 1, 64, 128]\n",
      "Tensor([ [-6.09375, 27.25, -39.25, 8.1875, -21.625, 0.265625, -18.375, 3.6875, 9.375, -21, 77, -4.84375, -7.78125, -25.5, -32.75, 11.625, -20.25, 0.515625, 21.75, 10, 31.375, 3.39062, -8.3125, -26, -36.25, -46.75, 26.625, 24.125, 9.6875, -50, 11, 16.25, -2.15625, 3.53125, 9, -0.00976562, -13.75, 22.25, 2.32812, -5.28125, 11, -24.625, -45.25, 30.125, -0.140625, -0.859375, -9.625, 7.8125, 16.125, -17.75, -20.125, -20.625, 5.28125, -6.15625, -13.5625, 30.375, 32.25, 3.76562, -42.5, -1.28125, 3.5625, 1.69531, 12.3125, -0.902344, 11.4375, -13.3125, -11.375, -24.375, -25.875, 6.09375, 33.5, -54.75, 31.125, -28.375, 31.125, -23.875, -9, 9.875, 5, 23.625, 0.625, -10.3125, -6.5, 13.4375, -5.125, -5.40625, 7.75, 5.4375, -15.125, -17.625, -25.75, -2.76562, -35, 21.125, -33.25, -6.59375, -17.75, -24.5, -9.0625, -25.5, -11.375, -20.875, 12.5, -21.75, -19.5, 10.8125, -18.25, 16.375, -36, 3.34375, 17.75, -12.75, 16.875, -6.3125, -41.25, 6.09375, -0.351562, -14.375, 32.75, -54.5, 48.5, 32.75, -18.625, 7.4375, -1.59375, 1.8125, -18.875, 37.5]], dtype=bfloat16 )\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Printing torch tensor\n",
      "torch.Size([1, 1, 64, 128])\n",
      "tensor([[-6.0938e+00,  2.7250e+01, -3.9250e+01,  8.1875e+00, -2.1625e+01,\n",
      "          2.6562e-01, -1.8375e+01,  3.6875e+00,  9.3750e+00, -2.1000e+01,\n",
      "          7.7000e+01, -4.8438e+00, -7.7812e+00, -2.5500e+01, -3.2750e+01,\n",
      "          1.1625e+01, -2.0250e+01,  5.1562e-01,  2.1750e+01,  1.0000e+01,\n",
      "          3.1375e+01,  3.3906e+00, -8.3125e+00, -2.6000e+01, -3.6250e+01,\n",
      "         -4.6750e+01,  2.6625e+01,  2.4125e+01,  9.6875e+00, -5.0000e+01,\n",
      "          1.1000e+01,  1.6250e+01, -2.1562e+00,  3.5312e+00,  9.0000e+00,\n",
      "         -9.7656e-03, -1.3750e+01,  2.2250e+01,  2.3281e+00, -5.2812e+00,\n",
      "          1.1000e+01, -2.4625e+01, -4.5250e+01,  3.0125e+01, -1.4062e-01,\n",
      "         -8.5938e-01, -9.6250e+00,  7.8125e+00,  1.6125e+01, -1.7750e+01,\n",
      "         -2.0125e+01, -2.0625e+01,  5.2812e+00, -6.1562e+00, -1.3562e+01,\n",
      "          3.0375e+01,  3.2250e+01,  3.7656e+00, -4.2500e+01, -1.2812e+00,\n",
      "          3.5625e+00,  1.6953e+00,  1.2312e+01, -9.0234e-01,  1.1438e+01,\n",
      "         -1.3312e+01, -1.1375e+01, -2.4375e+01, -2.5875e+01,  6.0938e+00,\n",
      "          3.3500e+01, -5.4750e+01,  3.1125e+01, -2.8375e+01,  3.1125e+01,\n",
      "         -2.3875e+01, -9.0000e+00,  9.8750e+00,  5.0000e+00,  2.3625e+01,\n",
      "          6.2500e-01, -1.0312e+01, -6.5000e+00,  1.3438e+01, -5.1250e+00,\n",
      "         -5.4062e+00,  7.7500e+00,  5.4375e+00, -1.5125e+01, -1.7625e+01,\n",
      "         -2.5750e+01, -2.7656e+00, -3.5000e+01,  2.1125e+01, -3.3250e+01,\n",
      "         -6.5938e+00, -1.7750e+01, -2.4500e+01, -9.0625e+00, -2.5500e+01,\n",
      "         -1.1375e+01, -2.0875e+01,  1.2500e+01, -2.1750e+01, -1.9500e+01,\n",
      "          1.0812e+01, -1.8250e+01,  1.6375e+01, -3.6000e+01,  3.3438e+00,\n",
      "          1.7750e+01, -1.2750e+01,  1.6875e+01, -6.3125e+00, -4.1250e+01,\n",
      "          6.0938e+00, -3.5156e-01, -1.4375e+01,  3.2750e+01, -5.4500e+01,\n",
      "          4.8500e+01,  3.2750e+01, -1.8625e+01,  7.4375e+00, -1.5938e+00,\n",
      "          1.8125e+00, -1.8875e+01,  3.7500e+01]], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "print(\"Printing ttnn tensor\")\n",
    "print(output.shape)\n",
    "print(output[0, 0, :1])\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Printing torch tensor\")\n",
    "torch_output = ttnn.to_torch(output)\n",
    "print(torch_output.shape)\n",
    "print(torch_output[0, 0, :1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m                  Metal\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Closing device 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttl.device.CloseDevice(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
