{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m                  Metal\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Initializing device 0\n",
      "\u001b[38;2;000;128;000m                 Device\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Opening device driver\n",
      "\u001b[32m2023-10-30 16:03:36.602\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Detected 4 PCI devices\n",
      "\u001b[32m2023-10-30 16:03:36.629\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Using 1 Hugepages/NumHostMemChannels for TTDevice (pci_interface_id: 3 device_id: 0xfaca revision: 0)\n",
      "\u001b[32m2023-10-30 16:03:36.635\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Using 1 Hugepages/NumHostMemChannels for TTDevice (pci_interface_id: 2 device_id: 0xfaca revision: 0)\n",
      "\u001b[32m2023-10-30 16:03:36.639\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Using 1 Hugepages/NumHostMemChannels for TTDevice (pci_interface_id: 1 device_id: 0xfaca revision: 0)\n",
      "\u001b[32m2023-10-30 16:03:36.647\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Using 1 Hugepages/NumHostMemChannels for TTDevice (pci_interface_id: 0 device_id: 0xfaca revision: 0)\n",
      "\u001b[32m2023-10-30 16:03:36.723\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Disable PCIE DMA\n",
      "\u001b[32m2023-10-30 16:03:36.723\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Disable PCIE DMA\n",
      "\u001b[32m2023-10-30 16:03:36.723\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Disable PCIE DMA\n",
      "\u001b[32m2023-10-30 16:03:36.723\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Disable PCIE DMA\n",
      "\u001b[38;2;000;128;000m                  Metal\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | AI CLK for device 0 is:   1202 MHz\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import ttnn\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device_id = 0\n",
    "device = ttnn.open(device_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "sequence_size = 64\n",
    "num_heads = 4\n",
    "head_size = 32\n",
    "hidden_size = num_heads * head_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize activations and weights using torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_hidden_states = torch.randn((batch_size, sequence_size, hidden_size), dtype=torch.bfloat16)\n",
    "\n",
    "torch_attention_mask = torch.zeros((1, 1, 1, sequence_size), dtype=torch.bfloat16)\n",
    "torch_attention_mask[:, :, ::2, :] = -1e9\n",
    "\n",
    "torch_query_weight = torch.randn((hidden_size, hidden_size), dtype=torch.bfloat16)\n",
    "torch_query_bias = torch.randn((1, 1, 1, hidden_size), dtype=torch.bfloat16)\n",
    "torch_key_weight = torch.randn((hidden_size, hidden_size), dtype=torch.bfloat16)\n",
    "torch_key_bias = torch.randn((1, 1, 1, hidden_size), dtype=torch.bfloat16)\n",
    "torch_value_weight = torch.randn((hidden_size, hidden_size), dtype=torch.bfloat16)\n",
    "torch_value_bias = torch.randn((1, 1, 1, hidden_size), dtype=torch.bfloat16)\n",
    "torch_output_weight = torch.randn((hidden_size, hidden_size), dtype=torch.bfloat16)\n",
    "torch_output_bias = torch.randn((1, 1, 1, hidden_size), dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert activations and weights to ttnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states = ttnn.from_torch(torch_hidden_states)\n",
    "attention_mask = ttnn.from_torch(torch_attention_mask)\n",
    "\n",
    "query_weight = ttnn.from_torch(torch_query_weight)\n",
    "query_bias = ttnn.from_torch(torch_query_bias)\n",
    "key_weight = ttnn.from_torch(torch_key_weight)\n",
    "key_bias = ttnn.from_torch(torch_key_bias)\n",
    "value_weight = ttnn.from_torch(torch_value_weight)\n",
    "value_bias = ttnn.from_torch(torch_value_bias)\n",
    "output_weight = ttnn.from_torch(torch_output_weight)\n",
    "output_bias = ttnn.from_torch(torch_output_bias)\n",
    "\n",
    "hidden_states = ttnn.to_device(hidden_states, device)\n",
    "attention_mask = ttnn.to_device(attention_mask, device)\n",
    "query_weight = ttnn.to_device(query_weight, device)\n",
    "query_bias = ttnn.to_device(query_bias, device, memory_config=ttnn.L1_MEMORY_CONFIG)\n",
    "key_weight = ttnn.to_device(key_weight, device)\n",
    "key_bias = ttnn.to_device(key_bias, device, memory_config=ttnn.L1_MEMORY_CONFIG)\n",
    "value_weight = ttnn.to_device(value_weight, device)\n",
    "value_bias = ttnn.to_device(value_bias, device, memory_config=ttnn.L1_MEMORY_CONFIG)\n",
    "output_weight = ttnn.to_device(output_weight, device)\n",
    "output_bias = ttnn.to_device(output_bias, device, memory_config=ttnn.L1_MEMORY_CONFIG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write multi_head_attention using ttnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_head_attention(\n",
    "    hidden_states,\n",
    "    attention_mask,\n",
    "    query_weight,\n",
    "    query_bias,\n",
    "    key_weight,\n",
    "    key_bias,\n",
    "    value_weight,\n",
    "    value_bias,\n",
    "    output_weight,\n",
    "    output_bias,\n",
    "    *,\n",
    "    head_size,\n",
    "):\n",
    "    batch_size, sequence_size, hidden_size = hidden_states.shape\n",
    "    num_heads = hidden_size // head_size\n",
    "\n",
    "    query = hidden_states @ query_weight\n",
    "    query = query + query_bias\n",
    "    query = ttnn.reshape(query, (batch_size, sequence_size, num_heads, head_size))\n",
    "    query = ttnn.permute(query, (0, 2, 1, 3))\n",
    "\n",
    "    key = hidden_states @ key_weight\n",
    "    key = key + key_bias\n",
    "    key = ttnn.reshape(key, (batch_size, sequence_size, num_heads, head_size))\n",
    "    key = ttnn.permute(key, (0, 2, 3, 1))\n",
    "\n",
    "    value = hidden_states @ value_weight\n",
    "    value = value + value_bias\n",
    "    value = ttnn.reshape(value, (batch_size, sequence_size, num_heads, head_size))\n",
    "    value = ttnn.permute(value, (0, 2, 1, 3))\n",
    "\n",
    "    attention_scores = query @ key\n",
    "    attention_scores = attention_scores * (1 / (head_size**0.5))\n",
    "    if attention_mask is not None:\n",
    "        attention_scores = attention_scores + attention_mask\n",
    "\n",
    "    attention_probs = ttnn.softmax(attention_scores, dim=-1)\n",
    "\n",
    "    context_layer = attention_probs @ value\n",
    "    context_layer = ttnn.permute(context_layer, (0, 2, 1, 3))\n",
    "    context_layer = ttnn.reshape(context_layer, (batch_size, sequence_size, hidden_size))\n",
    "\n",
    "    self_output = context_layer @ output_weight\n",
    "    self_output = self_output + output_bias\n",
    "\n",
    "    return self_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run multi_head_attention using ttnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-30 16:03:39.412 | WARNING  | ttnn.core:reshape:524 - reshape from [1, 64, 128] to (1, 64, 4, 32) could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-30 16:03:39.756 | WARNING  | ttnn.core:permute:543 - permute of tensor with shape [1, 64, 4, 32] using order (0, 2, 1, 3) could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-30 16:03:39.761 | WARNING  | ttnn.core:reshape:524 - reshape from [1, 64, 128] to (1, 64, 4, 32) could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-30 16:03:39.762 | WARNING  | ttnn.core:permute:543 - permute of tensor with shape [1, 64, 4, 32] using order (0, 2, 3, 1) could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-30 16:03:39.765 | WARNING  | ttnn.core:reshape:524 - reshape from [1, 64, 128] to (1, 64, 4, 32) could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-30 16:03:39.766 | WARNING  | ttnn.core:permute:543 - permute of tensor with shape [1, 64, 4, 32] using order (0, 2, 1, 3) could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-30 16:03:42.642 | WARNING  | ttnn.core:permute:543 - permute of tensor with shape [1, 4, 64, 32] using order (0, 2, 1, 3) could not be run on the TT device. Defaulting to torch implementation\n"
     ]
    }
   ],
   "source": [
    "output = multi_head_attention(\n",
    "    hidden_states,\n",
    "    attention_mask,\n",
    "    query_weight,\n",
    "    query_bias,\n",
    "    key_weight,\n",
    "    key_bias,\n",
    "    value_weight,\n",
    "    value_bias,\n",
    "    output_weight,\n",
    "    output_bias,\n",
    "    head_size=head_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing ttnn tensor\n",
      "[1, 64, 128]\n",
      "Tensor([ [23, 3.625, -3.21875, -12.375, 8.8125, -2.15625, 27.125, -5.5, -7.21875, -26.5, -2.78125, 10.125, -16.875, -22.5, -21, 11.1875, -12.75, 3.32812, -2.78125, 0.5625, -2.48438, -6.5, -0.179688, -24, 14.3125, 32.25, -5.40625, -17.625, 2.48438, -1.28125, 24.5, 6.9375, -21.375, 37.75, 12.25, -6.9375, 11.375, 1.02344, 23.875, -5.5625, -28.375, 6, 4.78125, 8.875, 4.625, 23.125, -2.15625, -14.75, 17.75, -2.20312, 11.6875, -28.375, -27.625, -14.5625, 9.0625, -13, 1.04688, -11.25, 8.5625, 6.0625, 21.625, -17.5, -5.53125, -11.25, 25.875, -0.0986328, 1.39062, -6.53125, -9.875, 7.4375, -6.78125, 2.65625, -32.5, -13.375, 14.375, 12.875, -3.32812, 7.625, 9.4375, 20.875, -5.21875, -6.84375, 0.671875, 18.625, -23.625, -23.25, -8.1875, -5.40625, 12.75, 9.75, -16.75, 1.20312, 11.6875, 4.65625, -7.25, -11.625, -13.375, -17, -0.3125, -8.9375, -18.875, 21.5, 42, -18.5, 3.25, -12, 1.35938, -5.03125, 8.0625, -19.5, 26, 2.46875, -0.953125, 15.9375, -4.15625, 7.09375, 18.875, -2.78125, -18.375, -4.59375, 20.375, -6.78125, -3.875, -26, 6.5, -14.1875, -8.125, 6]], dtype=bfloat16 )\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Printing torch tensor\n",
      "torch.Size([1, 64, 128])\n",
      "tensor([[ 23.0000,   3.6250,  -3.2188, -12.3750,   8.8125,  -2.1562,  27.1250,\n",
      "          -5.5000,  -7.2188, -26.5000,  -2.7812,  10.1250, -16.8750, -22.5000,\n",
      "         -21.0000,  11.1875, -12.7500,   3.3281,  -2.7812,   0.5625,  -2.4844,\n",
      "          -6.5000,  -0.1797, -24.0000,  14.3125,  32.2500,  -5.4062, -17.6250,\n",
      "           2.4844,  -1.2812,  24.5000,   6.9375, -21.3750,  37.7500,  12.2500,\n",
      "          -6.9375,  11.3750,   1.0234,  23.8750,  -5.5625, -28.3750,   6.0000,\n",
      "           4.7812,   8.8750,   4.6250,  23.1250,  -2.1562, -14.7500,  17.7500,\n",
      "          -2.2031,  11.6875, -28.3750, -27.6250, -14.5625,   9.0625, -13.0000,\n",
      "           1.0469, -11.2500,   8.5625,   6.0625,  21.6250, -17.5000,  -5.5312,\n",
      "         -11.2500,  25.8750,  -0.0986,   1.3906,  -6.5312,  -9.8750,   7.4375,\n",
      "          -6.7812,   2.6562, -32.5000, -13.3750,  14.3750,  12.8750,  -3.3281,\n",
      "           7.6250,   9.4375,  20.8750,  -5.2188,  -6.8438,   0.6719,  18.6250,\n",
      "         -23.6250, -23.2500,  -8.1875,  -5.4062,  12.7500,   9.7500, -16.7500,\n",
      "           1.2031,  11.6875,   4.6562,  -7.2500, -11.6250, -13.3750, -17.0000,\n",
      "          -0.3125,  -8.9375, -18.8750,  21.5000,  42.0000, -18.5000,   3.2500,\n",
      "         -12.0000,   1.3594,  -5.0312,   8.0625, -19.5000,  26.0000,   2.4688,\n",
      "          -0.9531,  15.9375,  -4.1562,   7.0938,  18.8750,  -2.7812, -18.3750,\n",
      "          -4.5938,  20.3750,  -6.7812,  -3.8750, -26.0000,   6.5000, -14.1875,\n",
      "          -8.1250,   6.0000]], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "print(\"Printing ttnn tensor\")\n",
    "output = ttnn.to_layout(output, ttnn.ROW_MAJOR_LAYOUT)\n",
    "output = ttnn.from_device(output)\n",
    "print(output.shape)\n",
    "print(output[0, :1])\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Printing torch tensor\")\n",
    "torch_output = ttnn.to_torch(output)\n",
    "print(torch_output.shape)\n",
    "print(torch_output[0, :1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttnn.free(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m                  Metal\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Closing device 0\n"
     ]
    }
   ],
   "source": [
    "ttnn.close(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
