{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ttnn\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device_id = 0\n",
    "device = ttnn.open(device_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "sequence_size = 64\n",
    "num_heads = 4\n",
    "head_size = 32\n",
    "hidden_size = num_heads * head_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize activations and weights using torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_hidden_states = torch.randn((batch_size, sequence_size, hidden_size), dtype=torch.bfloat16)\n",
    "\n",
    "torch_attention_mask = torch.zeros((1, 1, 1, sequence_size), dtype=torch.bfloat16)\n",
    "torch_attention_mask[:, :, ::2, :] = -1e9\n",
    "\n",
    "torch_query_weight = torch.randn((hidden_size, hidden_size), dtype=torch.bfloat16)\n",
    "torch_query_bias = torch.randn((1, 1, 1, hidden_size), dtype=torch.bfloat16)\n",
    "torch_key_weight = torch.randn((hidden_size, hidden_size), dtype=torch.bfloat16)\n",
    "torch_key_bias = torch.randn((1, 1, 1, hidden_size), dtype=torch.bfloat16)\n",
    "torch_value_weight = torch.randn((hidden_size, hidden_size), dtype=torch.bfloat16)\n",
    "torch_value_bias = torch.randn((1, 1, 1, hidden_size), dtype=torch.bfloat16)\n",
    "torch_output_weight = torch.randn((hidden_size, hidden_size), dtype=torch.bfloat16)\n",
    "torch_output_bias = torch.randn((1, 1, 1, hidden_size), dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert activations and weights to ttnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states = ttnn.from_torch(torch_hidden_states)\n",
    "attention_mask = ttnn.from_torch(torch_attention_mask)\n",
    "\n",
    "query_weight = ttnn.from_torch(torch_query_weight)\n",
    "query_bias = ttnn.from_torch(torch_query_bias)\n",
    "key_weight = ttnn.from_torch(torch_key_weight)\n",
    "key_bias = ttnn.from_torch(torch_key_bias)\n",
    "value_weight = ttnn.from_torch(torch_value_weight)\n",
    "value_bias = ttnn.from_torch(torch_value_bias)\n",
    "output_weight = ttnn.from_torch(torch_output_weight)\n",
    "output_bias = ttnn.from_torch(torch_output_bias)\n",
    "\n",
    "hidden_states = ttnn.to_device(hidden_states, device)\n",
    "attention_mask = ttnn.to_device(attention_mask, device)\n",
    "query_weight = ttnn.to_device(query_weight, device)\n",
    "query_bias = ttnn.to_device(query_bias, device, ttnn.l1_buffer_type)\n",
    "key_weight = ttnn.to_device(key_weight, device)\n",
    "key_bias = ttnn.to_device(key_bias, device, ttnn.l1_buffer_type)\n",
    "value_weight = ttnn.to_device(value_weight, device)\n",
    "value_bias = ttnn.to_device(value_bias, device, ttnn.l1_buffer_type)\n",
    "output_weight = ttnn.to_device(output_weight, device)\n",
    "output_bias = ttnn.to_device(output_bias, device, ttnn.l1_buffer_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write multi_head_attention using ttnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_head_attention(\n",
    "    hidden_states,\n",
    "    attention_mask,\n",
    "    query_weight,\n",
    "    query_bias,\n",
    "    key_weight,\n",
    "    key_bias,\n",
    "    value_weight,\n",
    "    value_bias,\n",
    "    output_weight,\n",
    "    output_bias,\n",
    "    *,\n",
    "    head_size,\n",
    "):\n",
    "    batch_size, sequence_size, hidden_size = hidden_states.shape\n",
    "    num_heads = hidden_size // head_size\n",
    "\n",
    "    query = hidden_states @ query_weight\n",
    "    query = query + query_bias\n",
    "    query = ttnn.reshape(query, (batch_size, sequence_size, num_heads, head_size))\n",
    "    query = ttnn.permute(query, (0, 2, 1, 3))\n",
    "\n",
    "    key = hidden_states @ key_weight\n",
    "    key = key + key_bias\n",
    "    key = ttnn.reshape(key, (batch_size, sequence_size, num_heads, head_size))\n",
    "    key = ttnn.permute(key, (0, 2, 3, 1))\n",
    "\n",
    "    value = hidden_states @ value_weight\n",
    "    value = value + value_bias\n",
    "    value = ttnn.reshape(value, (batch_size, sequence_size, num_heads, head_size))\n",
    "    value = ttnn.permute(value, (0, 2, 1, 3))\n",
    "\n",
    "    attention_scores = query @ key\n",
    "    attention_scores = attention_scores * (1 / (head_size**0.5))\n",
    "    if attention_mask is not None:\n",
    "        attention_scores = attention_scores + attention_mask\n",
    "\n",
    "    attention_probs = ttnn.softmax(attention_scores, dim=-1)\n",
    "\n",
    "    context_layer = attention_probs @ value\n",
    "    context_layer = ttnn.permute(context_layer, (0, 2, 1, 3))\n",
    "    context_layer = ttnn.reshape(context_layer, (batch_size, sequence_size, hidden_size))\n",
    "\n",
    "    self_output = context_layer @ output_weight\n",
    "    self_output = self_output + output_bias\n",
    "\n",
    "    return self_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run using ttnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-26 22:08:28.638 | WARNING  | ttnn.core:reshape:476 - Given reshape operation could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-26 22:08:28.649 | WARNING  | ttnn.core:reshape:476 - Given reshape operation could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-26 22:08:28.664 | WARNING  | ttnn.core:reshape:476 - Given reshape operation could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-26 22:08:28.674 | WARNING  | ttnn.core:reshape:476 - Given reshape operation could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-26 22:08:28.693 | WARNING  | ttnn.core:reshape:476 - Given reshape operation could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-26 22:08:28.704 | WARNING  | ttnn.core:reshape:476 - Given reshape operation could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-26 22:08:28.751 | WARNING  | ttnn.core:reshape:476 - Given reshape operation could not be run on the TT device. Defaulting to torch implementation\n",
      "2023-10-26 22:08:28.760 | WARNING  | ttnn.core:reshape:476 - Given reshape operation could not be run on the TT device. Defaulting to torch implementation\n"
     ]
    }
   ],
   "source": [
    "output = multi_head_attention(\n",
    "    hidden_states,\n",
    "    attention_mask,\n",
    "    query_weight,\n",
    "    query_bias,\n",
    "    key_weight,\n",
    "    key_bias,\n",
    "    value_weight,\n",
    "    value_bias,\n",
    "    output_weight,\n",
    "    output_bias,\n",
    "    head_size=head_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing ttnn tensor\n",
      "[1, 64, 128]\n",
      "Tensor([ 28.75], dtype=bfloat16 )\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Printing torch tensor\n",
      "torch.Size([1, 64, 128])\n",
      "tensor([28.7500], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "print(\"Printing ttnn tensor\")\n",
    "output = ttnn.from_device(output)\n",
    "print(output.shape)\n",
    "print(output[0, 0, :1])\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Printing torch tensor\")\n",
    "torch_output = ttnn.to_torch(output)\n",
    "print(torch_output.shape)\n",
    "print(torch_output[0, 0, :1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttnn.free(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m                  Metal\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Closing device 0\n"
     ]
    }
   ],
   "source": [
    "ttnn.close(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
