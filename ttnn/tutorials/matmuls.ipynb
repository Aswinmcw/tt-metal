{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3df30554-a78c-4399-96cd-bb5ab4de3a81",
   "metadata": {},
   "source": [
    "# Imports & open Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e5a51ab-9a4f-4f35-aaf1-dad1de004e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m                  Metal\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Initializing device 0\n",
      "\u001b[38;2;000;128;000m                 Device\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Opening user mode device driver\n",
      "\u001b[32m2024-01-05 02:04:45.117\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Detected 1 PCI device\n",
      "\u001b[32m2024-01-05 02:04:45.139\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Using 1 Hugepages/NumHostMemChannels for TTDevice (pci_interface_id: 0 device_id: 0xfaca revision: 0)\n",
      "\u001b[32m2024-01-05 02:04:45.221\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Disable PCIE DMA\n",
      "\u001b[38;2;000;128;000m                  Metal\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | AI CLK for device 0 is:   1202 MHz\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import ttnn\n",
    "\n",
    "torch.manual_seed(0)\n",
    "device_id = 0\n",
    "device = ttnn.open(device_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfcfccc-3e4c-4327-acb9-ed212f431857",
   "metadata": {},
   "source": [
    "# Enable program cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48974510-eb55-40b8-a46c-2bb9c19b5c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Program Cache: enabled.\n"
     ]
    }
   ],
   "source": [
    "ttnn.enable_program_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250960d7-3ad5-4dbc-bf1b-d8a49cfbb47b",
   "metadata": {},
   "source": [
    "# Matrix Multiplications "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a41311-6792-4ffc-91f6-6a8f6cfef4f0",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c30e3eb2-33a6-40ab-a50b-e97eb20671ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 8\n",
    "n = 12\n",
    "s = 384\n",
    "h = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409e0a34-9d0e-422e-8067-7256ab06c836",
   "metadata": {},
   "source": [
    "# Define matrix A and B and place them on DRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8725fb54-59b2-4995-a615-d7529cb08612",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn((b, s, h), dtype=torch.bfloat16)\n",
    "A = ttnn.from_torch(A)\n",
    "# tilize before matmul\n",
    "A = ttnn.to_layout(A, ttnn.TILE_LAYOUT)\n",
    "A = ttnn.to_device(A, device, memory_config=ttnn.DRAM_MEMORY_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5da7b6d9-b71f-487b-a02a-904a25d6328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = torch.randn((h, h), dtype=torch.bfloat16)\n",
    "B = ttnn.from_torch(B)\n",
    "B = ttnn.to_layout(B, ttnn.TILE_LAYOUT)\n",
    "B = ttnn.to_device(B, device, memory_config=ttnn.DRAM_MEMORY_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456e8fcc-9a31-46c1-a763-863abf84047b",
   "metadata": {},
   "source": [
    "# Define matrix C and D and place them on L1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31d2f989-c6f1-4c40-827c-4ce8fa6588e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((h, s), dtype=torch.bfloat16)\n",
    "C = ttnn.from_torch(C)\n",
    "C = ttnn.to_layout(C, ttnn.TILE_LAYOUT)\n",
    "C = ttnn.to_device(C, device, memory_config=ttnn.L1_MEMORY_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "391474a1-a08d-447b-81a9-caaa4ce67f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = torch.randn((s, s), dtype=torch.bfloat16)\n",
    "D = ttnn.from_torch(D)\n",
    "D = ttnn.to_layout(D, ttnn.TILE_LAYOUT)\n",
    "D = ttnn.to_device(D, device, memory_config=ttnn.L1_MEMORY_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a20c736-ab3b-445e-a413-5a16c746623b",
   "metadata": {},
   "source": [
    "# Matmul 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f7911f-6d07-48e4-988f-9dce3d52396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "M1 = ttnn.matmul(\n",
    "        A,\n",
    "        B,\n",
    "        memory_config=ttnn.DRAM_MEMORY_CONFIG,\n",
    "        dtype=ttnn.bfloat16, \n",
    "        core_grid=(b, n),\n",
    "        #core_grid=(6,6),\n",
    "    )\n",
    "R1 = ttnn.add(M1, M1, memory_config=ttnn.DRAM_MEMORY_CONFIG,)\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "print(\"Took: \" +  str(duration) + \" seconds!\")\n",
    "R1 = ttnn.to_layout(R1, ttnn.ROW_MAJOR_LAYOUT)\n",
    "print(R1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad413218-dff4-4206-b231-b1998687e328",
   "metadata": {},
   "source": [
    "# Rerun matmul to take advantage of program cache speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acab0b7f-8bd9-4d9e-8d42-cfc081f30b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "M1 = ttnn.matmul(\n",
    "        A,\n",
    "        B,\n",
    "        memory_config=ttnn.DRAM_MEMORY_CONFIG,\n",
    "        dtype=ttnn.bfloat16, \n",
    "        core_grid=(b, n),\n",
    "        #core_grid=(6,6),\n",
    "    )\n",
    "R1 = ttnn.add(M1, M1, memory_config=ttnn.DRAM_MEMORY_CONFIG,)\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "print(\"Took: \" +  str(duration) + \" seconds!\")\n",
    "R1 = ttnn.to_layout(R1, ttnn.ROW_MAJOR_LAYOUT)\n",
    "print(R1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c349433d-8cc3-4c17-a747-421702017282",
   "metadata": {},
   "source": [
    "### Use L1 memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2546c1-b5d4-4433-933f-d5b21acd29cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-dfine matrices A and B and place them on L1 memory \n",
    "A = torch.randn((b, s, h), dtype=torch.bfloat16)\n",
    "A = ttnn.from_torch(A)\n",
    "# tilize before matmul\n",
    "A = ttnn.to_layout(A, ttnn.TILE_LAYOUT)\n",
    "# put on L1 moemory \n",
    "A = ttnn.to_device(A, device, memory_config=ttnn.L1_MEMORY_CONFIG)\n",
    "\n",
    "\n",
    "B = torch.randn((h, h), dtype=torch.bfloat16)\n",
    "B = ttnn.from_torch(B)\n",
    "B = ttnn.to_layout(B, ttnn.TILE_LAYOUT)\n",
    "B = ttnn.to_device(B, device, memory_config=ttnn.L1_MEMORY_CONFIG)\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "M1 = ttnn.matmul(\n",
    "        A,\n",
    "        B,\n",
    "        memory_config=ttnn.L1_MEMORY_CONFIG, # place on L1 memory\n",
    "        dtype=ttnn.bfloat16, \n",
    "        core_grid=(b, n),\n",
    "    )\n",
    "R1 = ttnn.add(M1, M1, memory_config=ttnn.L1_MEMORY_CONFIG) # place on L1 memory\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "print(\"Took: \" +  str(duration) + \" seconds!\")\n",
    "#R1 = ttnn.to_layout(R1, ttnn.ROW_MAJOR_LAYOUT)\n",
    "#print(R1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa3b5a0-0785-4beb-9383-c3445dfb25fe",
   "metadata": {},
   "source": [
    "# Rerun matmul to take advantage of program cache speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ffb7b7-45d9-4cd3-aa4c-5ce6a9cc4b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "M1 = ttnn.matmul(\n",
    "        A,\n",
    "        B,\n",
    "        memory_config=ttnn.L1_MEMORY_CONFIG, # place on L1 memory\n",
    "        dtype=ttnn.bfloat16, \n",
    "        core_grid=(b, n),\n",
    "    )\n",
    "R1 = ttnn.add(M1, M1, memory_config=ttnn.L1_MEMORY_CONFIG) # place on L1 memory\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "print(\"Took: \" +  str(duration) + \" seconds!\")\n",
    "#R1 = ttnn.to_layout(R1, ttnn.ROW_MAJOR_LAYOUT)\n",
    "#print(R1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaf4371-d820-45d6-bb70-ab7a9d1f511c",
   "metadata": {},
   "source": [
    "# Matmul 2 : data type bfloat8_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5106bd48-6078-4251-a31a-ec0689444b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "M2 = ttnn.matmul(\n",
    "        R1,\n",
    "        C,\n",
    "        memory_config=ttnn.L1_MEMORY_CONFIG,\n",
    "        dtype=ttnn.bfloat8_b, # use float8 data type\n",
    "        core_grid=(b, n), # specify grid cores to run matmul on\n",
    "    )\n",
    "R2 = ttnn.add(M2, M2, memory_config=ttnn.L1_MEMORY_CONFIG) # place on L1 memory\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "print(\"Took: \" +  str(duration) + \" seconds!\")\n",
    "R2 = ttnn.to_layout(R1, ttnn.ROW_MAJOR_LAYOUT)\n",
    "print(R2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec60a336-51d6-43fb-8414-6164d058aaeb",
   "metadata": {},
   "source": [
    "# Rerun matmul to take advantage of program cache speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651d143c-6057-4149-8913-07e6b09cae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "M2 = ttnn.matmul(\n",
    "        R1,\n",
    "        C,\n",
    "        memory_config=ttnn.L1_MEMORY_CONFIG,\n",
    "        dtype=ttnn.bfloat8_b, # use float8 data type\n",
    "        core_grid=(b, n), # specify grid cores to run matmul on\n",
    "    )\n",
    "R2 = ttnn.add(M2, M2, memory_config=ttnn.L1_MEMORY_CONFIG) # place on L1 memory\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "print(\"Took: \" +  str(duration) + \" seconds!\")\n",
    "R2 = ttnn.to_layout(R1, ttnn.ROW_MAJOR_LAYOUT)\n",
    "print(R2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce8052c-8188-43c4-bc2e-2c09a0281b7d",
   "metadata": {},
   "source": [
    "# the dtype did not speed up the matmul, is this due to L1 fragmentation? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed808e4c-a60a-4127-8044-9bb81e0b9fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn((b, s, h), dtype=torch.bfloat16)\n",
    "A = ttnn.from_torch(A)\n",
    "# tilize before matmul\n",
    "A = ttnn.to_layout(A, ttnn.TILE_LAYOUT)\n",
    "A = ttnn.to_device(A, device, memory_config=ttnn.DRAM_MEMORY_CONFIG)\n",
    "\n",
    "B = torch.randn((h, h), dtype=torch.bfloat16)\n",
    "B = ttnn.from_torch(B)\n",
    "B = ttnn.to_layout(B, ttnn.TILE_LAYOUT)\n",
    "B = ttnn.to_device(B, device, memory_config=ttnn.DRAM_MEMORY_CONFIG)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "M1 = ttnn.matmul(\n",
    "        A,\n",
    "        B,\n",
    "        memory_config=ttnn.DRAM_MEMORY_CONFIG,\n",
    "        dtype=ttnn.bfloat8_b, \n",
    "        core_grid=(b, n),\n",
    "    )\n",
    "R1 = ttnn.add(M1, M1, memory_config=ttnn.DRAM_MEMORY_CONFIG)\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "print(\"Took: \" +  str(duration) + \" seconds!\")\n",
    "R1 = ttnn.to_layout(R1, ttnn.ROW_MAJOR_LAYOUT)\n",
    "print(R1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e654d85e-5278-4335-ad3d-3257a44aa6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "M1 = ttnn.matmul(\n",
    "        A,\n",
    "        B,\n",
    "        memory_config=ttnn.DRAM_MEMORY_CONFIG,\n",
    "        dtype=ttnn.bfloat8_b, \n",
    "        core_grid=(b, n),\n",
    "    )\n",
    "R1 = ttnn.add(M1, M1, memory_config=ttnn.DRAM_MEMORY_CONFIG,)\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "print(\"Took: \" +  str(duration) + \" seconds!\")\n",
    "R1 = ttnn.to_layout(R1, ttnn.ROW_MAJOR_LAYOUT)\n",
    "print(R1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f380b2a-dcc6-4599-ad56-c1a75f1b5210",
   "metadata": {},
   "source": [
    "# Matmul3 followed by softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a318ba-06ce-40fd-baf6-c6ea268f6d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start = time.time()\n",
    "#M3 = ttnn.matmul(\n",
    "#        M2,\n",
    "#        D,\n",
    "#        memory_config=ttnn.L1_MEMORY_CONFIG,\n",
    "#        dtype=ttnn.bfloat8_b, # use float8 data type\n",
    "#        core_grid=(b, n), # specify grid cores to run matmul on\n",
    "#    )\n",
    "\n",
    "#ttnn.softmax\n",
    "#R3 = ttnn.softmax(M3, -1)\n",
    "#end = time.time()\n",
    "#duration = end - start\n",
    "#print(\"Took: \" +  str(duration) + \" seconds!\")\n",
    "#R3 = ttnn.to_layout(R3, ttnn.ROW_MAJOR_LAYOUT)\n",
    "#print(R3[:, 1:10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b94cdd-e6ec-4167-9178-9708f2603f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun matmul to take advantage of program cache speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a858cf9-27c4-4b78-bc40-bead179c9e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start = time.time()\n",
    "#M3 = ttnn.matmul(\n",
    "#        M2,\n",
    "#        D,\n",
    "#        memory_config=ttnn.L1_MEMORY_CONFIG,\n",
    "#        dtype=ttnn.bfloat8_b, # use float8 data type\n",
    "#        core_grid=(b, n), # specify grid cores to run matmul on\n",
    "#    )\n",
    "\n",
    "#ttnn.softmax\n",
    "#R3 = ttnn.softmax(M3, -1)\n",
    "#end = time.time()\n",
    "#duration = end - start\n",
    "#print(\"Took: \" +  str(duration) + \" seconds!\")\n",
    "#R3 = ttnn.to_layout(R3, ttnn.ROW_MAJOR_LAYOUT)\n",
    "#print(R3[:, 1:10, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97aa98d-0bcf-4f2b-9e04-e5d20737fc58",
   "metadata": {},
   "source": [
    "# Time different batch size and grid core size combinations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2327f6d-4ea6-4316-9799-7f490f11def3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m                 Always\u001b[0m | \u001b[1m\u001b[38;2;255;000;000mFATAL   \u001b[0m | mcast_in1 is not implemented yet.\n",
      "\u001b[38;2;000;128;000m                 Always\u001b[0m | \u001b[1m\u001b[38;2;255;000;000mFATAL   \u001b[0m | mcast_in1 is not implemented yet.\n",
      "\u001b[38;2;000;128;000m                 Always\u001b[0m | \u001b[1m\u001b[38;2;255;000;000mFATAL   \u001b[0m | mcast_in1 is not implemented yet.\n",
      "\u001b[38;2;000;128;000m                 Always\u001b[0m | \u001b[1m\u001b[38;2;255;000;000mFATAL   \u001b[0m | Statically allocated circular buffers on core range [(x=0,y=0) - (x=1,y=1)] grow to 1564672 B which is beyond max L1 size of 1048576 B\n",
      "\u001b[38;2;000;128;000m                 Always\u001b[0m | \u001b[1m\u001b[38;2;255;000;000mFATAL   \u001b[0m | mcast_in1 is not implemented yet.\n",
      "\u001b[38;2;000;128;000m                 Always\u001b[0m | \u001b[1m\u001b[38;2;255;000;000mFATAL   \u001b[0m | Statically allocated circular buffers on core range [(x=0,y=0) - (x=1,y=1)] grow to 2154496 B which is beyond max L1 size of 1048576 B\n",
      "\u001b[38;2;000;128;000m                 Always\u001b[0m | \u001b[1m\u001b[38;2;255;000;000mFATAL   \u001b[0m | mcast_in1 is not implemented yet.\n",
      "\u001b[38;2;000;128;000m                 Always\u001b[0m | \u001b[1m\u001b[38;2;255;000;000mFATAL   \u001b[0m | Statically allocated circular buffers on core range [(x=0,y=0) - (x=1,y=1)] grow to 2744320 B which is beyond max L1 size of 1048576 B\n",
      "\u001b[38;2;000;128;000m                 Always\u001b[0m | \u001b[1m\u001b[38;2;255;000;000mFATAL   \u001b[0m | Statically allocated circular buffers in program 45 clash with L1 buffers on core range [(x=0,y=0) - (x=3,y=3)]. L1 buffer allocated at 972800 and static circular buffer region ends at 1040384\n",
      "\u001b[38;2;000;128;000m                 Always\u001b[0m | \u001b[1m\u001b[38;2;255;000;000mFATAL   \u001b[0m | mcast_in1 is not implemented yet.\n",
      "\u001b[38;2;000;128;000m                 Always\u001b[0m | \u001b[1m\u001b[38;2;255;000;000mFATAL   \u001b[0m | Statically allocated circular buffers on core range [(x=0,y=0) - (x=1,y=1)] grow to 3334144 B which is beyond max L1 size of 1048576 B\n",
      "\u001b[38;2;000;128;000m                 Always\u001b[0m | \u001b[1m\u001b[38;2;255;000;000mFATAL   \u001b[0m | Statically allocated circular buffers on core range [(x=0,y=0) - (x=3,y=3)] grow to 1236992 B which is beyond max L1 size of 1048576 B\n"
     ]
    }
   ],
   "source": [
    "batch = [1, 2, 4, 6, 8, 10]\n",
    "grid = [1, 2, 4, 6, 8, 10]\n",
    "\n",
    "for b in batch:\n",
    "    for g in grid:\n",
    "        A = torch.randn((b, s, h), dtype=torch.bfloat16)\n",
    "        A = ttnn.from_torch(A)\n",
    "        # tilize before matmul\n",
    "        A = ttnn.to_layout(A, ttnn.TILE_LAYOUT)\n",
    "        A = ttnn.to_device(A, device, memory_config=ttnn.L1_MEMORY_CONFIG)\n",
    "\n",
    "        B = torch.randn((h, h), dtype=torch.bfloat16)\n",
    "        B = ttnn.from_torch(B)\n",
    "        B = ttnn.to_layout(B, ttnn.TILE_LAYOUT)\n",
    "        B = ttnn.to_device(B, device, memory_config=ttnn.L1_MEMORY_CONFIG)\n",
    "\n",
    "        try:\n",
    "            start = time.time()\n",
    "            M1 = ttnn.matmul(\n",
    "            A,\n",
    "            B,\n",
    "            memory_config=ttnn.DRAM_MEMORY_CONFIG,\n",
    "            dtype=ttnn.bfloat16, \n",
    "            core_grid=(g, g),\n",
    "            )\n",
    "            R1 = ttnn.add(M1, M1, memory_config=ttnn.DRAM_MEMORY_CONFIG,)\n",
    "            end = time.time()\n",
    "            duration = end - start\n",
    "            #print(\"\\n\")\n",
    "            #print(\"b: \" + str(b))\n",
    "            #print(\"g: \" + str(g))\n",
    "            #print(\"Took: \" +  str(duration) + \" seconds!\")\n",
    "            #print(\"\\n\")\n",
    "            #R1 = ttnn.to_layout(R1, ttnn.ROW_MAJOR_LAYOUT)\n",
    "            #print(R1.shape)\n",
    "        except Exception as E:\n",
    "            pass\n",
    "            #print(\"b is: \" + str(b) + \" g is: \" + str(g))\n",
    "            #print(\"ERROR!)\n",
    "            #print(\"Exception: \", E)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba81c01b-142a-4f98-bb34-a33478023a38",
   "metadata": {},
   "source": [
    "# Rerun matmul to take advantage of program cache speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8fd554f-021b-4da1-b56c-0855a028c09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b is: 1 g is: 1\n",
      "ERROR!\n",
      "\u001b[38;2;000;128;000m                 Always\u001b[0m | \u001b[1m\u001b[38;2;255;000;000mFATAL   \u001b[0m | mcast_in1 is not implemented yet.\n",
      "\n",
      "\n",
      "b: 1\n",
      "g: 2\n",
      "Took: 0.0008168220520019531 seconds!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "b: 1\n",
      "g: 4\n",
      "Took: 0.0007686614990234375 seconds!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "b: 1\n",
      "g: 6\n",
      "Took: 0.0007557868957519531 seconds!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "b: 1\n",
      "g: 8\n",
      "Took: 0.0008060932159423828 seconds!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "b: 1\n",
      "g: 10\n",
      "Took: 0.0007746219635009766 seconds!\n",
      "\n",
      "\n",
      "b is: 2 g is: 1\n",
      "ERROR!\n",
      "\u001b[38;2;000;128;000m                 Always\u001b[0m | \u001b[1m\u001b[38;2;255;000;000mFATAL   \u001b[0m | mcast_in1 is not implemented yet.\n",
      "\n",
      "\n",
      "b: 2\n",
      "g: 2\n",
      "Took: 0.0008080005645751953 seconds!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "b: 2\n",
      "g: 4\n",
      "Took: 0.0007913112640380859 seconds!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "b: 2\n",
      "g: 6\n",
      "Took: 0.0007541179656982422 seconds!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "b: 2\n",
      "g: 8\n",
      "Took: 0.0007760524749755859 seconds!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "b: 2\n",
      "g: 10\n",
      "Took: 0.0007596015930175781 seconds!\n",
      "\n",
      "\n",
      "b is: 4 g is: 1\n",
      "ERROR!\n",
      "\u001b[38;2;000;128;000m                 Always\u001b[0m | \u001b[1m\u001b[38;2;255;000;000mFATAL   \u001b[0m | mcast_in1 is not implemented yet.\n",
      "b is: 4 g is: 2\n",
      "ERROR!\n",
      "\u001b[38;2;000;128;000m                 Always\u001b[0m | \u001b[1m\u001b[38;2;255;000;000mFATAL   \u001b[0m | Statically allocated circular buffers on core range [(x=0,y=0) - (x=1,y=1)] grow to 1564672 B which is beyond max L1 size of 1048576 B\n",
      "\n",
      "\n",
      "b: 4\n",
      "g: 4\n",
      "Took: 0.0019562244415283203 seconds!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "b: 4\n",
      "g: 6\n",
      "Took: 0.0009205341339111328 seconds!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "b: 4\n",
      "g: 8\n",
      "Took: 0.0008847713470458984 seconds!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "b: 4\n",
      "g: 10\n",
      "Took: 0.0008893013000488281 seconds!\n",
      "\n",
      "\n",
      "b is: 6 g is: 1\n",
      "ERROR!\n",
      "\u001b[38;2;000;128;000m                 Always\u001b[0m | \u001b[1m\u001b[38;2;255;000;000mFATAL   \u001b[0m | mcast_in1 is not implemented yet.\n",
      "b is: 6 g is: 2\n",
      "ERROR!\n",
      "\u001b[38;2;000;128;000m                 Always\u001b[0m | \u001b[1m\u001b[38;2;255;000;000mFATAL   \u001b[0m | Statically allocated circular buffers on core range [(x=0,y=0) - (x=1,y=1)] grow to 2154496 B which is beyond max L1 size of 1048576 B\n",
      "\n",
      "\n",
      "b: 6\n",
      "g: 4\n",
      "Took: 0.0009143352508544922 seconds!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "b: 6\n",
      "g: 6\n",
      "Took: 0.0008904933929443359 seconds!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "b: 6\n",
      "g: 8\n",
      "Took: 0.0008995532989501953 seconds!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "b: 6\n",
      "g: 10\n",
      "Took: 0.0008974075317382812 seconds!\n",
      "\n",
      "\n",
      "b is: 8 g is: 1\u001b[38;2;000;128;000m                 Always\u001b[0m | \u001b[1m\u001b[38;2;255;000;000mFATAL   \u001b[0m | mcast_in1 is not implemented yet.\n",
      "\n",
      "ERROR!\n",
      "b is: 8 g is: 2\n",
      "ERROR!\n",
      "\u001b[38;2;000;128;000m                 Always\u001b[0m | \u001b[1m\u001b[38;2;255;000;000mFATAL   \u001b[0m | Statically allocated circular buffers on core range [(x=0,y=0) - (x=1,y=1)] grow to 2744320 B which is beyond max L1 size of 1048576 B\n",
      "b is: 8 g is: 4\u001b[38;2;000;128;000m                 Always\u001b[0m | \u001b[1m\u001b[38;2;255;000;000mFATAL   \u001b[0m | Statically allocated circular buffers in program 45 clash with L1 buffers on core range [(x=0,y=0) - (x=3,y=3)]. L1 buffer allocated at 972800 and static circular buffer region ends at 1040384\n",
      "\n",
      "ERROR!\n",
      "\n",
      "\n",
      "b: 8\n",
      "g: 6\n",
      "Took: 0.0006241798400878906 seconds!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "b: 8\n",
      "g: 8\n",
      "Took: 0.0005850791931152344 seconds!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "b: 8\n",
      "g: 10\n",
      "Took: 0.0005931854248046875 seconds!\n",
      "\n",
      "\n",
      "b is: 10 g is: 1\u001b[38;2;000;128;000m                 Always\u001b[0m | \u001b[1m\u001b[38;2;255;000;000mFATAL   \u001b[0m | mcast_in1 is not implemented yet.\n",
      "\n",
      "ERROR!\n",
      "b is: 10 g is: 2\n",
      "ERROR!\n",
      "\u001b[38;2;000;128;000m                 Always\u001b[0m | \u001b[1m\u001b[38;2;255;000;000mFATAL   \u001b[0m | Statically allocated circular buffers on core range [(x=0,y=0) - (x=1,y=1)] grow to 3334144 B which is beyond max L1 size of 1048576 B\n",
      "b is: 10 g is: 4\u001b[38;2;000;128;000m                 Always\u001b[0m | \u001b[1m\u001b[38;2;255;000;000mFATAL   \u001b[0m | Statically allocated circular buffers on core range [(x=0,y=0) - (x=3,y=3)] grow to 1236992 B which is beyond max L1 size of 1048576 B\n",
      "\n",
      "ERROR!\n",
      "\n",
      "\n",
      "b: 10\n",
      "g: 6\n",
      "Took: 0.0006067752838134766 seconds!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "b: 10\n",
      "g: 8\n",
      "Took: 0.0005898475646972656 seconds!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "b: 10\n",
      "g: 10\n",
      "Took: 0.0005807876586914062 seconds!\n",
      "\n",
      "\n",
      "['     ', 'grid1', 'grid2', 'grid4', 'grid6', 'grid8', 'grid10']\n",
      "['batch1', ' ERROR ', 0.000817, 0.000769, 0.000756, 0.000806, 0.000775]\n",
      "['batch2', ' ERROR ', 0.000808, 0.000791, 0.000754, 0.000776, 0.00076]\n",
      "['batch4', ' ERROR ', ' ERROR ', 0.001956, 0.000921, 0.000885, 0.000889]\n",
      "['batch6', ' ERROR ', ' ERROR ', 0.000914, 0.00089, 0.0009, 0.000897]\n",
      "['batch8', ' ERROR ', ' ERROR ', ' ERROR ', 0.000624, 0.000585, 0.000593]\n",
      "['batch10', ' ERROR ', ' ERROR ', ' ERROR ', 0.000607, 0.00059, 0.000581]\n"
     ]
    }
   ],
   "source": [
    "batch = [1, 2, 4, 6, 8, 10]\n",
    "grid = [1, 2, 4, 6, 8, 10]\n",
    "grids = [\"     \", \"grid1\", \"grid2\", \"grid4\", \"grid6\", \"grid8\", \"grid10\"]\n",
    "table = []\n",
    "table.append(grids)\n",
    "for b in batch:\n",
    "    row = []\n",
    "    row.append(\"batch\" + str(b))\n",
    "    for g in grid:\n",
    "        A = torch.randn((b, s, h), dtype=torch.bfloat16)\n",
    "        A = ttnn.from_torch(A)\n",
    "        # tilize before matmul\n",
    "        A = ttnn.to_layout(A, ttnn.TILE_LAYOUT)\n",
    "        A = ttnn.to_device(A, device, memory_config=ttnn.L1_MEMORY_CONFIG)\n",
    "\n",
    "        B = torch.randn((h, h), dtype=torch.bfloat16)\n",
    "        B = ttnn.from_torch(B)\n",
    "        B = ttnn.to_layout(B, ttnn.TILE_LAYOUT)\n",
    "        B = ttnn.to_device(B, device, memory_config=ttnn.L1_MEMORY_CONFIG)\n",
    "\n",
    "        try:\n",
    "            start = time.time()\n",
    "            M1 = ttnn.matmul(\n",
    "            A,\n",
    "            B,\n",
    "            memory_config=ttnn.DRAM_MEMORY_CONFIG,\n",
    "            dtype=ttnn.bfloat16, \n",
    "            core_grid=(g, g),\n",
    "            )\n",
    "            R1 = ttnn.add(M1, M1, memory_config=ttnn.DRAM_MEMORY_CONFIG,)\n",
    "            end = time.time()\n",
    "            duration = end - start\n",
    "            row.append(round(duration, 6))\n",
    "            print(\"\\n\")\n",
    "            print(\"b: \" + str(b))\n",
    "            print(\"g: \" + str(g))\n",
    "            print(\"Took: \" +  str(duration) + \" seconds!\")\n",
    "            print(\"\\n\")\n",
    "            #R1 = ttnn.to_layout(R1, ttnn.ROW_MAJOR_LAYOUT)\n",
    "            #print(R1.shape)\n",
    "        except Exception as E:\n",
    "            row.append(\" ERROR \")\n",
    "            print(\"b is: \" + str(b) + \" g is: \" + str(g))\n",
    "            print(\"ERROR!\")\n",
    "            #print(\"Exception: \", E)\n",
    "    table.append(row)\n",
    "\n",
    "for row in table:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a5ce54-d661-4752-a705-e94eba60c7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = [['Row {} Col {}'.format(row + 1, col +1) for col in range(6)] for row in range(6)]\n",
    "for row in table:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db470d86-9672-48f8-a94d-64bf7039a2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttnn.close(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed328a7-447f-4f00-94ed-9f766dcd95b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff69f093-a3a1-4c5c-9489-7ca956c43a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e158ba-61d1-4e31-8d21-7d1e82ecd563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3024623-af0c-47d0-8f1c-873490f1bb9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b020f7-381f-4d9a-ba5c-5b93afc6dda4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423e4693-eac8-470a-9a70-865925d88b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttnn.close(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef75262d-9b38-4587-b99e-49fc9e55403a",
   "metadata": {},
   "source": [
    "# Defragment L1 memory Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3f4945-f294-40a8-95bd-a2dc67ab971d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80876dd-c1ec-4963-b763-335fa429116d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99fbddf-d1f1-4b7d-9a5e-68d941a190c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
