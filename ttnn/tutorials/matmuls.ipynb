{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3df30554-a78c-4399-96cd-bb5ab4de3a81",
   "metadata": {},
   "source": [
    "# Imports & open Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e5a51ab-9a4f-4f35-aaf1-dad1de004e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m                  Metal\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Initializing device 0\n",
      "\u001b[38;2;000;128;000m                 Device\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Opening user mode device driver\n",
      "\u001b[32m2024-01-05 00:01:10.723\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Detected 1 PCI device\n",
      "\u001b[32m2024-01-05 00:01:10.738\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Using 1 Hugepages/NumHostMemChannels for TTDevice (pci_interface_id: 0 device_id: 0xfaca revision: 0)\n",
      "\u001b[32m2024-01-05 00:01:10.814\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Disable PCIE DMA\n",
      "\u001b[38;2;000;128;000m                  Metal\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | AI CLK for device 0 is:   1202 MHz\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import ttnn\n",
    "\n",
    "torch.manual_seed(0)\n",
    "device_id = 0\n",
    "device = ttnn.open(device_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfcfccc-3e4c-4327-acb9-ed212f431857",
   "metadata": {},
   "source": [
    "# Enable program cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48974510-eb55-40b8-a46c-2bb9c19b5c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Program Cache: enabled.\n"
     ]
    }
   ],
   "source": [
    "ttnn.enable_program_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250960d7-3ad5-4dbc-bf1b-d8a49cfbb47b",
   "metadata": {},
   "source": [
    "# Matrix Multiplications "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a41311-6792-4ffc-91f6-6a8f6cfef4f0",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c30e3eb2-33a6-40ab-a50b-e97eb20671ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 8\n",
    "n = 12\n",
    "s = 384\n",
    "h = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409e0a34-9d0e-422e-8067-7256ab06c836",
   "metadata": {},
   "source": [
    "# Define matrix A and B and place them on DRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8725fb54-59b2-4995-a615-d7529cb08612",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn((b, s, h), dtype=torch.bfloat16)\n",
    "A = ttnn.from_torch(A)\n",
    "# tilize before matmul\n",
    "A = ttnn.to_layout(A, ttnn.TILE_LAYOUT)\n",
    "A = ttnn.to_device(A, device, memory_config=ttnn.DRAM_MEMORY_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5da7b6d9-b71f-487b-a02a-904a25d6328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = torch.randn((h, h), dtype=torch.bfloat16)\n",
    "B = ttnn.from_torch(B)\n",
    "B = ttnn.to_layout(B, ttnn.TILE_LAYOUT)\n",
    "B = ttnn.to_device(B, device, memory_config=ttnn.DRAM_MEMORY_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456e8fcc-9a31-46c1-a763-863abf84047b",
   "metadata": {},
   "source": [
    "# Define matrix C and D and place them on L1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31d2f989-c6f1-4c40-827c-4ce8fa6588e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((h, s), dtype=torch.bfloat16)\n",
    "C = ttnn.from_torch(C)\n",
    "C = ttnn.to_layout(C, ttnn.TILE_LAYOUT)\n",
    "C = ttnn.to_device(C, device, memory_config=ttnn.L1_MEMORY_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "391474a1-a08d-447b-81a9-caaa4ce67f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = torch.randn((s, s), dtype=torch.bfloat16)\n",
    "D = ttnn.from_torch(D)\n",
    "D = ttnn.to_layout(D, ttnn.TILE_LAYOUT)\n",
    "D = ttnn.to_device(D, device, memory_config=ttnn.L1_MEMORY_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a20c736-ab3b-445e-a413-5a16c746623b",
   "metadata": {},
   "source": [
    "# Matmul 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57f7911f-6d07-48e4-988f-9dce3d52396a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 1.2370569705963135 seconds!\n",
      "[8, 384, 1024]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "M1 = ttnn.matmul(\n",
    "        A,\n",
    "        B,\n",
    "        memory_config=ttnn.DRAM_MEMORY_CONFIG,\n",
    "        dtype=ttnn.bfloat16, \n",
    "        core_grid=(b, n),\n",
    "        #core_grid=(6,6),\n",
    "    )\n",
    "R1 = ttnn.add(M1, M1, memory_config=ttnn.DRAM_MEMORY_CONFIG,)\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "print(\"Took: \" +  str(duration) + \" seconds!\")\n",
    "R1 = ttnn.to_layout(R1, ttnn.ROW_MAJOR_LAYOUT)\n",
    "print(R1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad413218-dff4-4206-b231-b1998687e328",
   "metadata": {},
   "source": [
    "# Rerun matmul to take advantage of program cache speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acab0b7f-8bd9-4d9e-8d42-cfc081f30b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 0.002558469772338867 seconds!\n",
      "[8, 384, 1024]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "M1 = ttnn.matmul(\n",
    "        A,\n",
    "        B,\n",
    "        memory_config=ttnn.DRAM_MEMORY_CONFIG,\n",
    "        dtype=ttnn.bfloat16, \n",
    "        core_grid=(b, n),\n",
    "        #core_grid=(6,6),\n",
    "    )\n",
    "R1 = ttnn.add(M1, M1, memory_config=ttnn.DRAM_MEMORY_CONFIG,)\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "print(\"Took: \" +  str(duration) + \" seconds!\")\n",
    "R1 = ttnn.to_layout(R1, ttnn.ROW_MAJOR_LAYOUT)\n",
    "print(R1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c349433d-8cc3-4c17-a747-421702017282",
   "metadata": {},
   "source": [
    "### Use L1 memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca2546c1-b5d4-4433-933f-d5b21acd29cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 0.567232608795166 seconds!\n"
     ]
    }
   ],
   "source": [
    "# Re-dfine matrices A and B and place them on L1 memory \n",
    "A = torch.randn((b, s, h), dtype=torch.bfloat16)\n",
    "A = ttnn.from_torch(A)\n",
    "# tilize before matmul\n",
    "A = ttnn.to_layout(A, ttnn.TILE_LAYOUT)\n",
    "# put on L1 moemory \n",
    "A = ttnn.to_device(A, device, memory_config=ttnn.L1_MEMORY_CONFIG)\n",
    "\n",
    "\n",
    "B = torch.randn((h, h), dtype=torch.bfloat16)\n",
    "B = ttnn.from_torch(B)\n",
    "B = ttnn.to_layout(B, ttnn.TILE_LAYOUT)\n",
    "B = ttnn.to_device(B, device, memory_config=ttnn.L1_MEMORY_CONFIG)\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "M1 = ttnn.matmul(\n",
    "        A,\n",
    "        B,\n",
    "        memory_config=ttnn.L1_MEMORY_CONFIG, # place on L1 memory\n",
    "        dtype=ttnn.bfloat16, \n",
    "        core_grid=(b, n),\n",
    "    )\n",
    "R1 = ttnn.add(M1, M1, memory_config=ttnn.L1_MEMORY_CONFIG) # place on L1 memory\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "print(\"Took: \" +  str(duration) + \" seconds!\")\n",
    "#R1 = ttnn.to_layout(R1, ttnn.ROW_MAJOR_LAYOUT)\n",
    "#print(R1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa3b5a0-0785-4beb-9383-c3445dfb25fe",
   "metadata": {},
   "source": [
    "# Rerun matmul to take advantage of program cache speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91ffb7b7-45d9-4cd3-aa4c-5ce6a9cc4b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 0.0025701522827148438 seconds!\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "M1 = ttnn.matmul(\n",
    "        A,\n",
    "        B,\n",
    "        memory_config=ttnn.L1_MEMORY_CONFIG, # place on L1 memory\n",
    "        dtype=ttnn.bfloat16, \n",
    "        core_grid=(b, n),\n",
    "    )\n",
    "R1 = ttnn.add(M1, M1, memory_config=ttnn.L1_MEMORY_CONFIG) # place on L1 memory\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "print(\"Took: \" +  str(duration) + \" seconds!\")\n",
    "#R1 = ttnn.to_layout(R1, ttnn.ROW_MAJOR_LAYOUT)\n",
    "#print(R1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaf4371-d820-45d6-bb70-ab7a9d1f511c",
   "metadata": {},
   "source": [
    "# Matmul 2 : data type bfloat8_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5106bd48-6078-4251-a31a-ec0689444b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 1.2832131385803223 seconds!\n",
      "[8, 384, 1024]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "M2 = ttnn.matmul(\n",
    "        R1,\n",
    "        C,\n",
    "        memory_config=ttnn.L1_MEMORY_CONFIG,\n",
    "        dtype=ttnn.bfloat8_b, # use float8 data type\n",
    "        core_grid=(b, n), # specify grid cores to run matmul on\n",
    "    )\n",
    "R2 = ttnn.add(M2, M2, memory_config=ttnn.L1_MEMORY_CONFIG) # place on L1 memory\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "print(\"Took: \" +  str(duration) + \" seconds!\")\n",
    "R2 = ttnn.to_layout(R1, ttnn.ROW_MAJOR_LAYOUT)\n",
    "print(R2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec60a336-51d6-43fb-8414-6164d058aaeb",
   "metadata": {},
   "source": [
    "# Rerun matmul to take advantage of program cache speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "651d143c-6057-4149-8913-07e6b09cae48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 0.0024156570434570312 seconds!\n",
      "[8, 384, 1024]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "M2 = ttnn.matmul(\n",
    "        R1,\n",
    "        C,\n",
    "        memory_config=ttnn.L1_MEMORY_CONFIG,\n",
    "        dtype=ttnn.bfloat8_b, # use float8 data type\n",
    "        core_grid=(b, n), # specify grid cores to run matmul on\n",
    "    )\n",
    "R2 = ttnn.add(M2, M2, memory_config=ttnn.L1_MEMORY_CONFIG) # place on L1 memory\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "print(\"Took: \" +  str(duration) + \" seconds!\")\n",
    "R2 = ttnn.to_layout(R1, ttnn.ROW_MAJOR_LAYOUT)\n",
    "print(R2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce8052c-8188-43c4-bc2e-2c09a0281b7d",
   "metadata": {},
   "source": [
    "# the dtype did not speed up the matmul, is this due to L1 fragmentation? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed808e4c-a60a-4127-8044-9bb81e0b9fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 0.701779842376709 seconds!\n",
      "[8, 384, 1024]\n"
     ]
    }
   ],
   "source": [
    "A = torch.randn((b, s, h), dtype=torch.bfloat16)\n",
    "A = ttnn.from_torch(A)\n",
    "# tilize before matmul\n",
    "A = ttnn.to_layout(A, ttnn.TILE_LAYOUT)\n",
    "A = ttnn.to_device(A, device, memory_config=ttnn.DRAM_MEMORY_CONFIG)\n",
    "\n",
    "B = torch.randn((h, h), dtype=torch.bfloat16)\n",
    "B = ttnn.from_torch(B)\n",
    "B = ttnn.to_layout(B, ttnn.TILE_LAYOUT)\n",
    "B = ttnn.to_device(B, device, memory_config=ttnn.DRAM_MEMORY_CONFIG)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "M1 = ttnn.matmul(\n",
    "        A,\n",
    "        B,\n",
    "        memory_config=ttnn.DRAM_MEMORY_CONFIG,\n",
    "        dtype=ttnn.bfloat8_b, \n",
    "        core_grid=(b, n),\n",
    "    )\n",
    "R1 = ttnn.add(M1, M1, memory_config=ttnn.DRAM_MEMORY_CONFIG)\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "print(\"Took: \" +  str(duration) + \" seconds!\")\n",
    "R1 = ttnn.to_layout(R1, ttnn.ROW_MAJOR_LAYOUT)\n",
    "print(R1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e654d85e-5278-4335-ad3d-3257a44aa6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 0.0016560554504394531 seconds!\n",
      "[8, 384, 1024]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "M1 = ttnn.matmul(\n",
    "        A,\n",
    "        B,\n",
    "        memory_config=ttnn.DRAM_MEMORY_CONFIG,\n",
    "        dtype=ttnn.bfloat8_b, \n",
    "        core_grid=(b, n),\n",
    "    )\n",
    "R1 = ttnn.add(M1, M1, memory_config=ttnn.DRAM_MEMORY_CONFIG,)\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "print(\"Took: \" +  str(duration) + \" seconds!\")\n",
    "R1 = ttnn.to_layout(R1, ttnn.ROW_MAJOR_LAYOUT)\n",
    "print(R1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f380b2a-dcc6-4599-ad56-c1a75f1b5210",
   "metadata": {},
   "source": [
    "# Matmul3 followed by softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a318ba-06ce-40fd-baf6-c6ea268f6d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "M3 = ttnn.matmul(\n",
    "        M2,\n",
    "        D,\n",
    "        memory_config=ttnn.L1_MEMORY_CONFIG,\n",
    "        dtype=ttnn.bfloat8_b, # use float8 data type\n",
    "        core_grid=(b, n), # specify grid cores to run matmul on\n",
    "    )\n",
    "\n",
    "#ttnn.softmax\n",
    "R3 = ttnn.softmax(M3, -1)\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "print(\"Took: \" +  str(duration) + \" seconds!\")\n",
    "R3 = ttnn.to_layout(R3, ttnn.ROW_MAJOR_LAYOUT)\n",
    "print(R3[:, 1:10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b94cdd-e6ec-4167-9178-9708f2603f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun matmul to take advantage of program cache speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a858cf9-27c4-4b78-bc40-bead179c9e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "M3 = ttnn.matmul(\n",
    "        M2,\n",
    "        D,\n",
    "        memory_config=ttnn.L1_MEMORY_CONFIG,\n",
    "        dtype=ttnn.bfloat8_b, # use float8 data type\n",
    "        core_grid=(b, n), # specify grid cores to run matmul on\n",
    "    )\n",
    "\n",
    "#ttnn.softmax\n",
    "R3 = ttnn.softmax(M3, -1)\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "print(\"Took: \" +  str(duration) + \" seconds!\")\n",
    "R3 = ttnn.to_layout(R3, ttnn.ROW_MAJOR_LAYOUT)\n",
    "print(R3[:, 1:10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423e4693-eac8-470a-9a70-865925d88b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttnn.close(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef75262d-9b38-4587-b99e-49fc9e55403a",
   "metadata": {},
   "source": [
    "# Defragment L1 memory Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3f4945-f294-40a8-95bd-a2dc67ab971d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80876dd-c1ec-4963-b763-335fa429116d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99fbddf-d1f1-4b7d-9a5e-68d941a190c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
